# accelerate launch train_rec.py --dataset redial_gen --tokenizer utils/dialogpt --model utils/dialogpt_model --text_tokenizer utils/roberta --text_encoder utils/roberta_model --n_prefix_rec 20 --prompt_encoder output_dir_inspired/prompt/dialogpt5e5_v1/final --num_train_epochs 20 --per_device_train_batch_size 32 --per_device_eval_batch_size 64 --gradient_accumulation_steps 1 --num_warmup_steps 530 --context_max_length 128 --prompt_max_length 128 --entity_max_length 32 --learning_rate 5e-4 --output_dir output_dir/rec/lr1e5 --use_wandb --project rec --name rec1e5 --log_all
accelerate launch train_rec.py --dataset redial_gen --tokenizer utils/dialogpt --model utils/dialogpt_model --text_tokenizer utils/roberta --text_encoder utils/roberta_model --n_prefix_rec 20 --prompt_encoder output_dir_inspired/prompt/dialogpt5e5_v1/best --num_train_epochs 10 --per_device_train_batch_size 32 --per_device_eval_batch_size 64 --gradient_accumulation_steps 1 --num_warmup_steps 530 --context_max_length 128 --prompt_max_length 128 --entity_max_length 32 --learning_rate 1e-3 --output_dir output_dir/rec/lr1e3 --use_wandb --project rec --name rec1e3 --log_all
accelerate launch train_rec.py --dataset redial_gen --tokenizer utils/dialogpt --model utils/dialogpt_model --text_tokenizer utils/roberta --text_encoder utils/roberta_model --n_prefix_rec 20 --prompt_encoder output_dir_inspired/prompt/dialogpt5e5_v1/best --num_train_epochs 10 --per_device_train_batch_size 32 --per_device_eval_batch_size 64 --gradient_accumulation_steps 1 --num_warmup_steps 530 --context_max_length 128 --prompt_max_length 128 --entity_max_length 32 --learning_rate 1e-4 --output_dir output_dir/rec/lr1e4 --use_wandb --project rec --name rec1e4 --log_all

# accelerate launch train_rec.py --dataset inspired_gen --tokenizer utils/dialogpt --model utils/dialogpt_model --text_tokenizer utils/roberta --text_encoder utils/roberta_model --n_prefix_rec 10 --prompt_encoder output_dir_inspired/prompt/dialogpt1e4/best --num_train_epochs 8 --per_device_train_batch_size 32 --per_device_eval_batch_size 64 --gradient_accumulation_steps 1 --num_warmup_steps 33 --context_max_length 128 --prompt_max_length 128 --entity_max_length 32 --learning_rate 1e-4 --output_dir output_dir_inspired/rec --use_wandb --project rec --name rec --log_all
# accelerate launch train_rec.py --dataset inspired_gen --tokenizer utils/dialogpt --model utils/dialogpt_model --text_tokenizer utils/roberta --text_encoder utils/roberta_model --n_prefix_rec 10 --prompt_encoder output_dir_inspired/prompt/dialogpt1e4/best --num_train_epochs 8 --per_device_train_batch_size 32 --per_device_eval_batch_size 64 --gradient_accumulation_steps 1 --num_warmup_steps 33 --context_max_length 128 --prompt_max_length 128 --entity_max_length 32 --learning_rate 5e-4 --output_dir output_dir_inspired/rec --use_wandb --project rec --name rec --log_all
